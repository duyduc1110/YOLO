{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T18:15:26.097032Z",
     "start_time": "2020-04-26T18:15:24.970218Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T18:15:26.116565Z",
     "start_time": "2020-04-26T18:15:26.098032Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def load_config():\n",
    "    modules = []\n",
    "    with open('yolov3.cfg', 'r', encoding='utf-8') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "        lines = [line.rstrip().lstrip() for line in lines if line != '' if line[0] != '#']\n",
    "\n",
    "        module = {}\n",
    "        for line in lines:\n",
    "            if line[0]=='[':\n",
    "                if len(module) > 0:\n",
    "                    modules.append(module)\n",
    "                module = {}\n",
    "                module['type'] = line[1:-1]\n",
    "            else:\n",
    "                key, value = line.split('=')\n",
    "                module[key.strip()] = value.strip()\n",
    "        modules.append(module)\n",
    "    return modules\n",
    "\n",
    "modules = load_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T18:15:26.161529Z",
     "start_time": "2020-04-26T18:15:26.118565Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "THRESH = 0.7\n",
    "BATCH_SIZE = 1\n",
    "WIDTH = 416\n",
    "HEIGHT = 416\n",
    "NUM_BOX = 3\n",
    "LABELS = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \\\n",
    "          \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \\\n",
    "          \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \\\n",
    "          \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \\\n",
    "          \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \\\n",
    "          \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \\\n",
    "          \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \\\n",
    "          \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \\\n",
    "          \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \\\n",
    "          \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, idx, in_f, module):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        self.create_module(idx, in_f, module)\n",
    "    \n",
    "    def create_module(self, idx, in_f, module):\n",
    "        self.out_f = int(module['filters'])\n",
    "        kernel_size = int(module['size'])\n",
    "        stride = int(module['stride'])\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.add_module('conv', \n",
    "                        nn.Conv2d(in_f, \n",
    "                                  self.out_f, \n",
    "                                  kernel_size, \n",
    "                                  stride, padding, \n",
    "                                  bias=False if 'batch_normalize' in module else True))\n",
    "        if 'batch_normalize' in module:\n",
    "            self.add_module('norm', nn.BatchNorm2d(self.out_f))\n",
    "        if module['activation'] == 'leaky':\n",
    "            self.add_module('leaky', nn.LeakyReLU(inplace=True))\n",
    "    \n",
    "    def get_out_features(self):\n",
    "        return self.out_f\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for sub_module in self.children():\n",
    "            x = sub_module(x)\n",
    "        return x\n",
    "\n",
    "class ShortcutLayer(nn.Module):\n",
    "    def __init__(self, pos):\n",
    "        super(ShortcutLayer, self).__init__()\n",
    "        self.pos = pos\n",
    "    def forward(self, x, y):\n",
    "        return x+y\n",
    "\n",
    "class RouteLayer(nn.Module):\n",
    "    def __init__(self, pos):\n",
    "        super(RouteLayer, self).__init__()\n",
    "        self.pos = [int(i) for i in pos.split(',')]\n",
    "    def forward(self, x):\n",
    "        return torch.cat(x, 1)\n",
    "\n",
    "class UpsampleLayer(nn.Module):\n",
    "    def __init__(self, scale):\n",
    "        super(UpsampleLayer, self).__init__()\n",
    "        self.up = nn.Upsample(scale_factor=scale)\n",
    "    def forward(self, x):\n",
    "        return self.up(x)\n",
    "\n",
    "class YOLOLayer(nn.Module):\n",
    "    def __init__(self, anchors=None):\n",
    "        super(YOLOLayer, self).__init__()\n",
    "        self.anchors = anchors\n",
    "    \n",
    "    def get_boxes(self, inputs=None):\n",
    "        grid_x = (torch.arange(self.input_w)\n",
    "                 .repeat(self.input_h,1)\n",
    "                 .view(1, self.input_w, self.input_h, 1)\n",
    "                 .repeat(BATCH_SIZE, 1, 1, NUM_BOX))\n",
    "        grid_y = (torch.arange(self.input_w)\n",
    "                 .repeat(self.input_h,1)\n",
    "                 .t()\n",
    "                 .view(1, self.input_w, self.input_h, 1)\n",
    "                 .repeat(BATCH_SIZE, 1, 1, NUM_BOX))\n",
    "        anchor_w = torch.tensor([w/self.stride for w, _ in self.anchors])\n",
    "        anchor_h = torch.tensor([h/self.stride for _, h in self.anchors])\n",
    "        \n",
    "        #Calculate bx, by, bw, bh\n",
    "        inputs[..., 0] += grid_x\n",
    "        inputs[..., 1] += grid_y\n",
    "        inputs[..., 2] = torch.exp(inputs[..., 2]) * anchor_w\n",
    "        inputs[..., 3] = torch.exp(inputs[..., 3]) * anchor_h\n",
    "        \n",
    "        #Truth ground boxes\n",
    "        inputs[..., :4] *= self.stride\n",
    "        \n",
    "        inputs = inputs.view(BATCH_SIZE, -1, 85)\n",
    "        \n",
    "        return inputs\n",
    "        \n",
    "    def forward(self, inputs=None, targets=None):\n",
    "        self.input_w = inputs.shape[-2]\n",
    "        self.input_h = inputs.shape[-1]\n",
    "        inputs = inputs.view(BATCH_SIZE, NUM_BOX, -1, self.input_w, self.input_h).permute(0,3,4,1,2).contiguous()\n",
    "        self.stride = WIDTH / self.input_w\n",
    "        \n",
    "        #Sigmoid x, y, po and pc\n",
    "        inputs[..., :2] = torch.sigmoid(inputs[..., :2])\n",
    "        inputs[..., 4:] = torch.sigmoid(inputs[..., 4:])\n",
    "        \n",
    "        return self.get_boxes(inputs=inputs)\n",
    "\n",
    "    \n",
    "class YOLO(nn.Module):\n",
    "    def __init__(self, modules):\n",
    "        super(YOLO, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.create_modules(modules)\n",
    "    \n",
    "    def create_modules(self, modules):\n",
    "        out_fs = [3]\n",
    "        for idx, module in enumerate(modules[1:]):\n",
    "            if module['type'] == 'convolutional':\n",
    "                in_f = out_fs[-1]\n",
    "                t = ConvLayer(idx, in_f, module)\n",
    "                f = t.get_out_features()\n",
    "                self.layers.append(t)\n",
    "            elif module['type'] == 'shortcut':\n",
    "                pos = int(module['from'])\n",
    "                t = ShortcutLayer(pos)\n",
    "                f = out_fs[-1]\n",
    "                self.layers.append(t)\n",
    "            elif module['type'] == 'route':\n",
    "                pos = module['layers']\n",
    "                t = RouteLayer(pos)\n",
    "                f = sum([out_fs[i] for i in t.pos])\n",
    "                self.layers.append(t)\n",
    "            elif module['type'] == 'upsample':\n",
    "                scale = module['stride']\n",
    "                t = UpsampleLayer(scale)\n",
    "                f = out_fs[-1]\n",
    "                self.layers.append(t)\n",
    "            elif module['type'] == 'yolo':\n",
    "                mask = [int(i) for i in module['mask'].split(',')]\n",
    "                anchors = [int(value) for value in module['anchors'].split(',')]\n",
    "                anchors = [(anchors[2*i], anchors[2*i+1]) for i in mask]\n",
    "                t = YOLOLayer(anchors=anchors)\n",
    "                f = out_fs[-1]\n",
    "                self.layers.append(t)\n",
    "            out_fs.append(f)\n",
    "            \n",
    "    def load_weights(self, weight_path=None):\n",
    "        with open(weight_path, 'rb') as f:\n",
    "            header = np.fromfile(f, dtype = np.int32, count = 5)\n",
    "            weights = np.fromfile(f, dtype = np.float32)\n",
    "            \n",
    "        idx_w = 0\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            if isinstance(layer, ConvLayer):\n",
    "                conv_layer = layer.conv\n",
    "                \n",
    "                #Load weights to batch norm or conv bias\n",
    "                if 'batch_normalize' in modules[idx+1]:\n",
    "                    bn_layer = layer.norm\n",
    "                    length = bn_layer.bias.numel()\n",
    "                    for i in ['bias', 'weight', 'running_mean', 'running_var']:\n",
    "                        x = getattr(bn_layer, i)\n",
    "                        weight_to_load = torch.from_numpy(weights[idx_w: idx_w+length])\n",
    "                        weight_to_load = weight_to_load.view_as(x.data)\n",
    "                        x.data.copy_(weight_to_load)\n",
    "                        idx_w += length\n",
    "                else:\n",
    "                    length = conv_layer.bias.numel()\n",
    "                    weight_to_load = torch.from_numpy(weights[idx_w: idx_w+length])\n",
    "                    weight_to_load = weight_to_load.view_as(layer.conv.bias.data)\n",
    "                    conv_layer.bias.data.copy_(weight_to_load)\n",
    "                    idx_w += length\n",
    "\n",
    "                #Load to conv weight\n",
    "                length = conv_layer.weight.numel()\n",
    "                weight_to_load = torch.from_numpy(weights[idx_w: idx_w+length])\n",
    "                weight_to_load = weight_to_load.view_as(conv_layer.weight.data)\n",
    "                conv_layer.weight.data.copy_(weight_to_load)\n",
    "                idx_w += length\n",
    "\n",
    "                print('Loaded to Conv #{}, weight index is {}'.format(idx, idx_w))\n",
    "\n",
    "    def create_bouding_boxes(self, inputs=None):\n",
    "        boxes = []\n",
    "        for i in range(inputs.shape[1]):\n",
    "            obj_score = inputs[0,i,4]\n",
    "            \n",
    "            if obj_score <= THRESH: \n",
    "                continue \n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        yolo_outputs = []\n",
    "        for idx, layer in enumerate(model.layers):\n",
    "            if isinstance(layer, ConvLayer):\n",
    "                x = layer(x)\n",
    "            elif isinstance(layer, ShortcutLayer):\n",
    "                x = layer(x, outputs[layer.pos])\n",
    "            elif isinstance(layer, RouteLayer):\n",
    "                temp = [outputs[i] for i in layer.pos]\n",
    "                x = layer(temp)\n",
    "            elif isinstance(layer, UpsampleLayer):\n",
    "                x = layer(x)\n",
    "            elif isinstance(layer, YOLOLayer):\n",
    "                yolo_output = layer(inputs=x)\n",
    "                yolo_outputs.append(yolo_output)\n",
    "                x = outputs[-1]\n",
    "            outputs.append(x)\n",
    "        yolo_outputs = torch.cat(yolo_outputs, 1)\n",
    "        \n",
    "        self.create_bouding_boxes(inputs=yolo_outputs)\n",
    "        \n",
    "        return yolo_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model & load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T18:15:26.877774Z",
     "start_time": "2020-04-26T18:15:26.162743Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded to Conv #0, weight index is 992\n",
      "Loaded to Conv #1, weight index is 19680\n",
      "Loaded to Conv #2, weight index is 21856\n",
      "Loaded to Conv #3, weight index is 40544\n",
      "Loaded to Conv #5, weight index is 114784\n",
      "Loaded to Conv #6, weight index is 123232\n",
      "Loaded to Conv #7, weight index is 197472\n",
      "Loaded to Conv #9, weight index is 205920\n",
      "Loaded to Conv #10, weight index is 280160\n",
      "Loaded to Conv #12, weight index is 576096\n",
      "Loaded to Conv #13, weight index is 609376\n",
      "Loaded to Conv #14, weight index is 905312\n",
      "Loaded to Conv #16, weight index is 938592\n",
      "Loaded to Conv #17, weight index is 1234528\n",
      "Loaded to Conv #19, weight index is 1267808\n",
      "Loaded to Conv #20, weight index is 1563744\n",
      "Loaded to Conv #22, weight index is 1597024\n",
      "Loaded to Conv #23, weight index is 1892960\n",
      "Loaded to Conv #25, weight index is 1926240\n",
      "Loaded to Conv #26, weight index is 2222176\n",
      "Loaded to Conv #28, weight index is 2255456\n",
      "Loaded to Conv #29, weight index is 2551392\n",
      "Loaded to Conv #31, weight index is 2584672\n",
      "Loaded to Conv #32, weight index is 2880608\n",
      "Loaded to Conv #34, weight index is 2913888\n",
      "Loaded to Conv #35, weight index is 3209824\n",
      "Loaded to Conv #37, weight index is 4391520\n",
      "Loaded to Conv #38, weight index is 4523616\n",
      "Loaded to Conv #39, weight index is 5705312\n",
      "Loaded to Conv #41, weight index is 5837408\n",
      "Loaded to Conv #42, weight index is 7019104\n",
      "Loaded to Conv #44, weight index is 7151200\n",
      "Loaded to Conv #45, weight index is 8332896\n",
      "Loaded to Conv #47, weight index is 8464992\n",
      "Loaded to Conv #48, weight index is 9646688\n",
      "Loaded to Conv #50, weight index is 9778784\n",
      "Loaded to Conv #51, weight index is 10960480\n",
      "Loaded to Conv #53, weight index is 11092576\n",
      "Loaded to Conv #54, weight index is 12274272\n",
      "Loaded to Conv #56, weight index is 12406368\n",
      "Loaded to Conv #57, weight index is 13588064\n",
      "Loaded to Conv #59, weight index is 13720160\n",
      "Loaded to Conv #60, weight index is 14901856\n",
      "Loaded to Conv #62, weight index is 19624544\n",
      "Loaded to Conv #63, weight index is 20150880\n",
      "Loaded to Conv #64, weight index is 24873568\n",
      "Loaded to Conv #66, weight index is 25399904\n",
      "Loaded to Conv #67, weight index is 30122592\n",
      "Loaded to Conv #69, weight index is 30648928\n",
      "Loaded to Conv #70, weight index is 35371616\n",
      "Loaded to Conv #72, weight index is 35897952\n",
      "Loaded to Conv #73, weight index is 40620640\n",
      "Loaded to Conv #75, weight index is 41146976\n",
      "Loaded to Conv #76, weight index is 45869664\n",
      "Loaded to Conv #77, weight index is 46396000\n",
      "Loaded to Conv #78, weight index is 51118688\n",
      "Loaded to Conv #79, weight index is 51645024\n",
      "Loaded to Conv #80, weight index is 56367712\n",
      "Loaded to Conv #81, weight index is 56629087\n",
      "Loaded to Conv #84, weight index is 56761183\n",
      "Loaded to Conv #87, weight index is 56958815\n",
      "Loaded to Conv #88, weight index is 58140511\n",
      "Loaded to Conv #89, weight index is 58272607\n",
      "Loaded to Conv #90, weight index is 59454303\n",
      "Loaded to Conv #91, weight index is 59586399\n",
      "Loaded to Conv #92, weight index is 60768095\n",
      "Loaded to Conv #93, weight index is 60898910\n",
      "Loaded to Conv #96, weight index is 60932190\n",
      "Loaded to Conv #99, weight index is 60981854\n",
      "Loaded to Conv #100, weight index is 61277790\n",
      "Loaded to Conv #101, weight index is 61311070\n",
      "Loaded to Conv #102, weight index is 61607006\n",
      "Loaded to Conv #103, weight index is 61640286\n",
      "Loaded to Conv #104, weight index is 61936222\n",
      "Loaded to Conv #105, weight index is 62001757\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(modules)\n",
    "model.load_weights('./weights/yolov3.weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T16:44:09.057495Z",
     "start_time": "2020-04-25T16:44:09.054503Z"
    }
   },
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T11:43:56.823868Z",
     "start_time": "2020-04-28T11:43:52.907142Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_input(image, net_h, net_w):\n",
    "    new_h, new_w, _ = image.shape\n",
    "\n",
    "    # determine the new size of the image\n",
    "    if (float(net_w)/new_w) < (float(net_h)/new_h):\n",
    "        new_h = (new_h * net_w)/new_w\n",
    "        new_w = net_w\n",
    "    else:\n",
    "        new_w = (new_w * net_h)/new_h\n",
    "        new_h = net_h\n",
    "\n",
    "    # resize the image to the new size\n",
    "    resized = cv2.resize(image[:,:,::-1]/255., (int(new_w), int(new_h)))\n",
    "\n",
    "    # embed the image into the standard letter box\n",
    "    new_image = np.ones((net_h, net_w, 3)) * 0.5\n",
    "    new_image[int((net_h-new_h)//2):int((net_h+new_h)//2), int((net_w-new_w)//2):int((net_w+new_w)//2), :] = resized\n",
    "    new_image = np.expand_dims(new_image, 0)\n",
    "\n",
    "    return new_image\n",
    "\n",
    "\n",
    "img = cv2.imread('dog.jpg')\n",
    "img_resized = cv2.resize(img[:,:,::-1], (WIDTH, HEIGHT))\n",
    "\n",
    "img_tensor = torch.tensor(img_resized, dtype=torch.float32).unsqueeze(0).permute(0,3,1,2).contiguous()\n",
    "img_tensor /= 255\n",
    "\n",
    "with torch.no_grad():\n",
    "    result = model(img_tensor)\n",
    "    result = result.view(-1,85)\n",
    "    result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T11:54:36.549032Z",
     "start_time": "2020-04-28T11:54:36.348733Z"
    }
   },
   "outputs": [],
   "source": [
    "NMS_THRESH = 0.45\n",
    "\n",
    "class BoundingBox:\n",
    "    def __init__(self, x_min, y_min, x_max, y_max, score, label, obj_score):\n",
    "        self.x_min = x_min\n",
    "        self.x_max = x_max\n",
    "        self.y_min = y_min\n",
    "        self.y_max = y_max\n",
    "        self.box = [self.x_min, self.y_min, self.x_max, self.y_max]\n",
    "        \n",
    "        self.score = score\n",
    "        self.label = label\n",
    "        self.obj_score = obj_score\n",
    "    \n",
    "    def _print(self):\n",
    "        print(self.x_min, self.y_min, self.x_max, self.y_max, self.score, self.label, self.obj_score)\n",
    "    \n",
    "\n",
    "def xywh2wywy(inputs=None):\n",
    "    x, y, w, h = inputs\n",
    "    x_min, x_max = x-w/2, x+w/2\n",
    "    y_min, y_max = y-h/2, y+h/2\n",
    "    \n",
    "    return torch.tensor([x_min, y_min, x_max, y_max], dtype=inputs.dtype)\n",
    "\n",
    "\n",
    "def iou(box1=None, box2=None):\n",
    "    x = [box1.x_min, box1.x_max, box2.x_min, box2.x_max]\n",
    "    y = [box1.y_min, box1.y_max, box2.y_min, box2.y_max]\n",
    "    \n",
    "    if x[1] < x[2] or x[3] < x[0] or y[1] < y[2] or y[3] < y[0]:\n",
    "        return 0\n",
    "    else:\n",
    "        inter_x = min(x[1]-x[2], x[3]-x[0])\n",
    "        inter_y = min(y[1]-y[2], y[3]-y[0])\n",
    "        inter = inter_x * inter_y\n",
    "        overlap = (x[1]-x[0])*(y[1]-y[0]) + (x[3]-x[2])*(y[3]-y[2]) - inter\n",
    "        iou = inter/overlap\n",
    "        \n",
    "        return iou\n",
    "\n",
    "    \n",
    "def nms(boxes=None):\n",
    "    for i in range(len(boxes)-1):\n",
    "        if boxes[i].score == 0:\n",
    "            continue\n",
    "        for j in range(i+1, len(boxes)):\n",
    "            if boxes[i].label != boxes[j].label:\n",
    "                break\n",
    "            if iou(boxes[i], boxes[j]) > NMS_THRESH:\n",
    "                boxes[j].score = 0\n",
    "            \n",
    "    return boxes\n",
    "\n",
    "\n",
    "def draw_boxes(img, boxes):\n",
    "    scale_x = img.shape[1] / WIDTH\n",
    "    scale_y = img.shape[0] / HEIGHT\n",
    "    \n",
    "    for b in boxes:\n",
    "        x_min = int(b.x_min * scale_x)\n",
    "        x_max = int(b.x_max * scale_x)\n",
    "        y_min = int(b.y_min * scale_y)\n",
    "        y_max = int(b.y_max * scale_y)\n",
    "        \n",
    "        cv2.rectangle(img, (x_min, y_min), (x_max, y_max), (0,255,0), 3)\n",
    "        cv2.putText(img, \n",
    "                    LABELS[b.label] + ' ' + str(b.obj_score), \n",
    "                    (x_min, y_min - 13), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    1e-3 * img.shape[0], \n",
    "                    (0,255,0), 2)\n",
    "        \n",
    "    return img  \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    boxes = []\n",
    "\n",
    "    for bbox in result:\n",
    "        if bbox[4] > THRESH:\n",
    "            #Generate bouding box information\n",
    "            x_min, y_min, x_max, y_max = xywh2wywy(bbox[:4])\n",
    "            score = bbox[4]\n",
    "            label = torch.argmax(bbox[5:])\n",
    "            obj_score = bbox[label+5]\n",
    "\n",
    "            box = BoundingBox(x_min.tolist()\n",
    "                              , y_min.tolist()\n",
    "                              , x_max.tolist()\n",
    "                              , y_max.tolist()\n",
    "                              , score.tolist()\n",
    "                              , label.tolist()\n",
    "                              , obj_score.tolist())\n",
    "\n",
    "            boxes.append(box)\n",
    "\n",
    "    # sort boxes base on label class\n",
    "    boxes.sort(key=lambda x: (x.label, -x.score))\n",
    "    \n",
    "    # nms boxes with NMS_THRESH value and filter boxes\n",
    "    boxes = nms(boxes)\n",
    "    boxes = [box for box in boxes if box.score > 0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T11:54:37.799857Z",
     "start_time": "2020-04-28T11:54:37.794861Z"
    }
   },
   "outputs": [],
   "source": [
    "img = draw_boxes(img, boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T11:56:05.621131Z",
     "start_time": "2020-04-28T11:55:01.471664Z"
    }
   },
   "outputs": [],
   "source": [
    "cv2.imshow(\"test\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "326.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 929.313,
   "position": {
    "height": "853.313px",
    "left": "1496.66px",
    "right": "20px",
    "top": "155px",
    "width": "341.641px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
