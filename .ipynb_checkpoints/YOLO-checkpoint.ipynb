{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T13:03:35.520184Z",
     "start_time": "2020-05-03T13:03:34.908155Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T13:03:35.528187Z",
     "start_time": "2020-05-03T13:03:35.521184Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def load_config():\n",
    "    modules = []\n",
    "    with open('yolov3.cfg', 'r', encoding='utf-8') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "        lines = [line.rstrip().lstrip() for line in lines if line != '' if line[0] != '#']\n",
    "\n",
    "        module = {}\n",
    "        for line in lines:\n",
    "            if line[0]=='[':\n",
    "                if len(module) > 0:\n",
    "                    modules.append(module)\n",
    "                module = {}\n",
    "                module['type'] = line[1:-1]\n",
    "            else:\n",
    "                key, value = line.split('=')\n",
    "                module[key.strip()] = value.strip()\n",
    "        modules.append(module)\n",
    "    return modules\n",
    "\n",
    "modules = load_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T13:03:35.571196Z",
     "start_time": "2020-05-03T13:03:35.529187Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, idx, in_f, module):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        self.create_module(idx, in_f, module)\n",
    "    \n",
    "    def create_module(self, idx, in_f, module):\n",
    "        self.out_f = int(module['filters'])\n",
    "        kernel_size = int(module['size'])\n",
    "        stride = int(module['stride'])\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.add_module('conv', \n",
    "                        nn.Conv2d(in_f, \n",
    "                                  self.out_f, \n",
    "                                  kernel_size, \n",
    "                                  stride, \n",
    "                                  padding, \n",
    "                                  bias=False if 'batch_normalize' in module else True))\n",
    "        if 'batch_normalize' in module:\n",
    "            self.add_module('norm', nn.BatchNorm2d(self.out_f))\n",
    "        if module['activation'] == 'leaky':\n",
    "            self.add_module('leaky', nn.LeakyReLU(0.1, inplace=True))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for sub_module in self.children():\n",
    "            x = sub_module(x)\n",
    "        return x\n",
    "\n",
    "class ShortcutLayer(nn.Module):\n",
    "    def __init__(self, pos):\n",
    "        super(ShortcutLayer, self).__init__()\n",
    "        self.pos = pos\n",
    "    def forward(self, x, y):\n",
    "        return x+y\n",
    "\n",
    "class RouteLayer(nn.Module):\n",
    "    def __init__(self, pos):\n",
    "        super(RouteLayer, self).__init__()\n",
    "        self.pos = [int(i) for i in pos.split(',')]\n",
    "    def forward(self, x):\n",
    "        return torch.cat(x, 1)\n",
    "\n",
    "class UpsampleLayer(nn.Module):\n",
    "    def __init__(self, scale):\n",
    "        super(UpsampleLayer, self).__init__()\n",
    "        self.up = nn.Upsample(scale_factor=scale)\n",
    "    def forward(self, x):\n",
    "        return self.up(x)\n",
    "\n",
    "class YOLOLayer(nn.Module):\n",
    "    def __init__(self, anchors=None):\n",
    "        super(YOLOLayer, self).__init__()\n",
    "        self.anchors = anchors\n",
    "    \n",
    "    def get_boxes(self, inputs=None):\n",
    "        grid_x = (torch.arange(self.input_w)\n",
    "                 .repeat(self.input_h,1)\n",
    "                 .view(1, self.input_w, self.input_h, 1)\n",
    "                 .repeat(BATCH_SIZE, 1, 1, NUM_BOX).to(DEVICE))\n",
    "        grid_y = (torch.arange(self.input_w)\n",
    "                 .repeat(self.input_h,1)\n",
    "                 .t()\n",
    "                 .view(1, self.input_w, self.input_h, 1)\n",
    "                 .repeat(BATCH_SIZE, 1, 1, NUM_BOX).to(DEVICE))\n",
    "        anchor_w = torch.tensor([w/self.stride for w, _ in self.anchors]).to(DEVICE)\n",
    "        anchor_h = torch.tensor([h/self.stride for _, h in self.anchors]).to(DEVICE)\n",
    "        \n",
    "        #Calculate bx, by, bw, bh\n",
    "        inputs[..., 0] += grid_x\n",
    "        inputs[..., 1] += grid_y\n",
    "        inputs[..., 2] = torch.exp(inputs[..., 2]) * anchor_w\n",
    "        inputs[..., 3] = torch.exp(inputs[..., 3]) * anchor_h\n",
    "        \n",
    "        #Truth ground boxes\n",
    "        inputs[..., :4] *= self.stride\n",
    "        \n",
    "        inputs = inputs.view(BATCH_SIZE, -1, 85)\n",
    "        \n",
    "        return inputs\n",
    "        \n",
    "    def forward(self, inputs=None, targets=None):\n",
    "        self.input_w = inputs.shape[-2]\n",
    "        self.input_h = inputs.shape[-1]\n",
    "        inputs = inputs.view(BATCH_SIZE, NUM_BOX, -1, self.input_w, self.input_h).permute(0,3,4,1,2).contiguous()\n",
    "        self.stride = WIDTH / self.input_w\n",
    "        \n",
    "        #Sigmoid x, y, po and pc\n",
    "        inputs[..., :2] = torch.sigmoid(inputs[..., :2])\n",
    "        inputs[..., 4:] = torch.sigmoid(inputs[..., 4:])\n",
    "        \n",
    "        return self.get_boxes(inputs=inputs)\n",
    "\n",
    "    \n",
    "class YOLO(nn.Module):\n",
    "    def __init__(self, modules):\n",
    "        super(YOLO, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.create_modules(modules)\n",
    "    \n",
    "    def create_modules(self, modules):\n",
    "        out_fs = [3]\n",
    "        for idx, module in enumerate(modules[1:]):\n",
    "            if module['type'] == 'convolutional':\n",
    "                in_f = out_fs[-1]\n",
    "                t = ConvLayer(idx, in_f, module)\n",
    "                f = t.out_f\n",
    "                self.layers.append(t)\n",
    "            elif module['type'] == 'shortcut':\n",
    "                pos = int(module['from'])\n",
    "                t = ShortcutLayer(pos)\n",
    "                f = out_fs[-1]\n",
    "                self.layers.append(t)\n",
    "            elif module['type'] == 'route':\n",
    "                pos = module['layers']\n",
    "                t = RouteLayer(pos)\n",
    "                f = sum([out_fs[i] for i in t.pos])\n",
    "                self.layers.append(t)\n",
    "            elif module['type'] == 'upsample':\n",
    "                scale = module['stride']\n",
    "                t = UpsampleLayer(scale)\n",
    "                f = out_fs[-1]\n",
    "                self.layers.append(t)\n",
    "            elif module['type'] == 'yolo':\n",
    "                mask = [int(i) for i in module['mask'].split(',')]\n",
    "                anchors = [int(value) for value in module['anchors'].split(',')]\n",
    "                anchors = [(anchors[2*i], anchors[2*i+1]) for i in mask]\n",
    "                t = YOLOLayer(anchors=anchors)\n",
    "                f = out_fs[-1]\n",
    "                self.layers.append(t)\n",
    "            out_fs.append(f)\n",
    "            \n",
    "    def load_weights(self, weight_path=None):\n",
    "        with open(weight_path, 'rb') as f:\n",
    "            header = np.fromfile(f, dtype = np.int32, count = 5)\n",
    "            weights = np.fromfile(f, dtype = np.float32)\n",
    "            \n",
    "        idx_w = 0\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            if isinstance(layer, ConvLayer):\n",
    "                conv_layer = layer.conv\n",
    "                \n",
    "                #Load weights to batch norm or conv bias\n",
    "                if 'batch_normalize' in modules[idx+1]:\n",
    "                    bn_layer = layer.norm\n",
    "                    length = bn_layer.bias.numel()\n",
    "                    for i in ['bias', 'weight', 'running_mean', 'running_var']:\n",
    "                        x = getattr(bn_layer, i)\n",
    "                        weight_to_load = torch.from_numpy(weights[idx_w: idx_w+length])\n",
    "                        weight_to_load = weight_to_load.view_as(x.data)\n",
    "                        if i in ['bias', 'weight']:\n",
    "                            x.data.copy_(weight_to_load)\n",
    "                        else:\n",
    "                            x.copy_(weight_to_load)\n",
    "                        idx_w += length\n",
    "                else:\n",
    "                    length = conv_layer.bias.numel()\n",
    "                    weight_to_load = torch.from_numpy(weights[idx_w: idx_w+length])\n",
    "                    weight_to_load = weight_to_load.view_as(layer.conv.bias.data)\n",
    "                    conv_layer.bias.data.copy_(weight_to_load)\n",
    "                    idx_w += length\n",
    "\n",
    "                #Load to conv weight\n",
    "                length = conv_layer.weight.numel()\n",
    "                weight_to_load = torch.from_numpy(weights[idx_w: idx_w+length])\n",
    "                weight_to_load = weight_to_load.view_as(conv_layer.weight.data)\n",
    "                conv_layer.weight.data.copy_(weight_to_load)\n",
    "                idx_w += length\n",
    "\n",
    "                print('Loaded to Conv #{}, weight index is {}'.format(idx, idx_w))\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        yolo_outputs = []\n",
    "        \n",
    "        for idx, layer in enumerate(model.layers):\n",
    "            if isinstance(layer, ConvLayer):\n",
    "                x = layer(x)\n",
    "            elif isinstance(layer, ShortcutLayer):\n",
    "                x = layer(x, outputs[layer.pos])\n",
    "            elif isinstance(layer, RouteLayer):\n",
    "                temp = [outputs[i] for i in layer.pos]\n",
    "                x = layer(temp)\n",
    "            elif isinstance(layer, UpsampleLayer):\n",
    "                x = layer(x)\n",
    "            elif isinstance(layer, YOLOLayer):\n",
    "                yolo_output = layer(inputs=x)\n",
    "                yolo_outputs.append(yolo_output)\n",
    "                x = outputs[-1]\n",
    "                \n",
    "            #print(x.shape)\n",
    "            outputs.append(x)\n",
    "            \n",
    "        yolo_outputs = torch.cat(yolo_outputs, 1)\n",
    "        \n",
    "        return yolo_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model & load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T13:03:37.582828Z",
     "start_time": "2020-05-03T13:03:35.572197Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded to Conv #0, weight index is 992\n",
      "Loaded to Conv #1, weight index is 19680\n",
      "Loaded to Conv #2, weight index is 21856\n",
      "Loaded to Conv #3, weight index is 40544\n",
      "Loaded to Conv #5, weight index is 114784\n",
      "Loaded to Conv #6, weight index is 123232\n",
      "Loaded to Conv #7, weight index is 197472\n",
      "Loaded to Conv #9, weight index is 205920\n",
      "Loaded to Conv #10, weight index is 280160\n",
      "Loaded to Conv #12, weight index is 576096\n",
      "Loaded to Conv #13, weight index is 609376\n",
      "Loaded to Conv #14, weight index is 905312\n",
      "Loaded to Conv #16, weight index is 938592\n",
      "Loaded to Conv #17, weight index is 1234528\n",
      "Loaded to Conv #19, weight index is 1267808\n",
      "Loaded to Conv #20, weight index is 1563744\n",
      "Loaded to Conv #22, weight index is 1597024\n",
      "Loaded to Conv #23, weight index is 1892960\n",
      "Loaded to Conv #25, weight index is 1926240\n",
      "Loaded to Conv #26, weight index is 2222176\n",
      "Loaded to Conv #28, weight index is 2255456\n",
      "Loaded to Conv #29, weight index is 2551392\n",
      "Loaded to Conv #31, weight index is 2584672\n",
      "Loaded to Conv #32, weight index is 2880608\n",
      "Loaded to Conv #34, weight index is 2913888\n",
      "Loaded to Conv #35, weight index is 3209824\n",
      "Loaded to Conv #37, weight index is 4391520\n",
      "Loaded to Conv #38, weight index is 4523616\n",
      "Loaded to Conv #39, weight index is 5705312\n",
      "Loaded to Conv #41, weight index is 5837408\n",
      "Loaded to Conv #42, weight index is 7019104\n",
      "Loaded to Conv #44, weight index is 7151200\n",
      "Loaded to Conv #45, weight index is 8332896\n",
      "Loaded to Conv #47, weight index is 8464992\n",
      "Loaded to Conv #48, weight index is 9646688\n",
      "Loaded to Conv #50, weight index is 9778784\n",
      "Loaded to Conv #51, weight index is 10960480\n",
      "Loaded to Conv #53, weight index is 11092576\n",
      "Loaded to Conv #54, weight index is 12274272\n",
      "Loaded to Conv #56, weight index is 12406368\n",
      "Loaded to Conv #57, weight index is 13588064\n",
      "Loaded to Conv #59, weight index is 13720160\n",
      "Loaded to Conv #60, weight index is 14901856\n",
      "Loaded to Conv #62, weight index is 19624544\n",
      "Loaded to Conv #63, weight index is 20150880\n",
      "Loaded to Conv #64, weight index is 24873568\n",
      "Loaded to Conv #66, weight index is 25399904\n",
      "Loaded to Conv #67, weight index is 30122592\n",
      "Loaded to Conv #69, weight index is 30648928\n",
      "Loaded to Conv #70, weight index is 35371616\n",
      "Loaded to Conv #72, weight index is 35897952\n",
      "Loaded to Conv #73, weight index is 40620640\n",
      "Loaded to Conv #75, weight index is 41146976\n",
      "Loaded to Conv #76, weight index is 45869664\n",
      "Loaded to Conv #77, weight index is 46396000\n",
      "Loaded to Conv #78, weight index is 51118688\n",
      "Loaded to Conv #79, weight index is 51645024\n",
      "Loaded to Conv #80, weight index is 56367712\n",
      "Loaded to Conv #81, weight index is 56629087\n",
      "Loaded to Conv #84, weight index is 56761183\n",
      "Loaded to Conv #87, weight index is 56958815\n",
      "Loaded to Conv #88, weight index is 58140511\n",
      "Loaded to Conv #89, weight index is 58272607\n",
      "Loaded to Conv #90, weight index is 59454303\n",
      "Loaded to Conv #91, weight index is 59586399\n",
      "Loaded to Conv #92, weight index is 60768095\n",
      "Loaded to Conv #93, weight index is 60898910\n",
      "Loaded to Conv #96, weight index is 60932190\n",
      "Loaded to Conv #99, weight index is 60981854\n",
      "Loaded to Conv #100, weight index is 61277790\n",
      "Loaded to Conv #101, weight index is 61311070\n",
      "Loaded to Conv #102, weight index is 61607006\n",
      "Loaded to Conv #103, weight index is 61640286\n",
      "Loaded to Conv #104, weight index is 61936222\n",
      "Loaded to Conv #105, weight index is 62001757\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = YOLO(modules)\n",
    "model.to(DEVICE)\n",
    "model.load_weights('./weights/yolov3.weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T16:44:09.057495Z",
     "start_time": "2020-04-25T16:44:09.054503Z"
    }
   },
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T13:03:38.340051Z",
     "start_time": "2020-05-03T13:03:37.583829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 85])\n"
     ]
    }
   ],
   "source": [
    "THRESH = 0.3\n",
    "BATCH_SIZE = 1\n",
    "WIDTH = 416\n",
    "HEIGHT = 416\n",
    "NUM_BOX = 3\n",
    "\n",
    "LABELS = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \\\n",
    "          \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \\\n",
    "          \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \\\n",
    "          \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \\\n",
    "          \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \\\n",
    "          \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \\\n",
    "          \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \\\n",
    "          \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \\\n",
    "          \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \\\n",
    "          \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "\n",
    "def letterbox_image(img, inp_dim):\n",
    "    img_w, img_h = img.shape[1], img.shape[0]\n",
    "    w, h = inp_dim\n",
    "    new_w = int(img_w * min(w/img_w, h/img_h))\n",
    "    new_h = int(img_h * min(w/img_w, h/img_h))\n",
    "    resized_image = cv2.resize(img, (new_w,new_h), interpolation = cv2.INTER_CUBIC)\n",
    "    \n",
    "    canvas = np.full((inp_dim[1], inp_dim[0], 3), 128)\n",
    "\n",
    "    canvas[(h-new_h)//2:(h-new_h)//2 + new_h,(w-new_w)//2:(w-new_w)//2 + new_w,  :] = resized_image\n",
    "    \n",
    "    return canvas / 255.0\n",
    "\n",
    "\n",
    "img = cv2.imread('test_person.jpg')\n",
    "'''\n",
    "img_resized = cv2.resize(img[:,:,::-1], (WIDTH, HEIGHT))\n",
    "img_tensor = torch.tensor(img_resized, dtype=torch.float32).unsqueeze(0).permute(0,3,1,2).contiguous()\n",
    "img_tensor /= 255\n",
    "'''\n",
    "'''\n",
    "img = cv2.resize(img, None, fx=0.4, fy=0.4)\n",
    "blob = cv2.dnn.blobFromImage(img, scalefactor=0.00392, size=(WIDTH, HEIGHT), mean=(0, 0, 0), swapRB=True, crop=False)\n",
    "img_tensor = torch.tensor(blob)\n",
    "'''\n",
    "\n",
    "img_ = letterbox_image(img, (WIDTH, HEIGHT))\n",
    "img_ = img_[:,:,::-1].transpose((2,0,1)).copy()\n",
    "img_tensor = torch.from_numpy(img_).float().unsqueeze(0).to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    result = model(img_tensor)\n",
    "    result = result[result[...,4] >= THRESH]\n",
    "    \n",
    "    result = result.detach().cpu()\n",
    "    print(result.shape)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T13:04:55.101603Z",
     "start_time": "2020-05-03T13:04:55.085600Z"
    }
   },
   "outputs": [],
   "source": [
    "def xywh2wywy(inputs=None):\n",
    "    x, y, w, h = inputs[:,0], inputs[:,1], inputs[:,2], inputs[:,3]\n",
    "    x_min, x_max = x - w/2, x + w/2\n",
    "    y_min, y_max = y - h/2, y + h/2\n",
    "    \n",
    "    return torch.cat((x_min.unsqueeze(1),\n",
    "                      y_min.unsqueeze(1),\n",
    "                      x_max.unsqueeze(1),\n",
    "                      y_max.unsqueeze(1)\n",
    "                     ), 1)\n",
    "\n",
    "\n",
    "def iou(b1=None, b2=None):\n",
    "    b1_x1, b1_y1, b1_x2, b1_y2 = b1\n",
    "    b2_x1, b2_y1, b2_x2, b2_y2 = b2\n",
    "    b1_area = (b1_x2-b1_x1+1) * (b1_y2-b1_y1+1)\n",
    "    b2_area = (b2_x2-b2_x1+1) * (b2_y2-b2_y1+1)\n",
    "    \n",
    "    xx1 = max(b1_x1, b2_x1)\n",
    "    yy1 = max(b1_y1, b2_y1)\n",
    "    xx2 = min(b1_x2, b2_x2)\n",
    "    yy2 = min(b1_y2, b2_y2)\n",
    "\n",
    "    \n",
    "    inter_area = (max(xx2-xx1+1,0)) * (max(yy2-yy1+1,0))\n",
    "    union_area = b1_area + b2_area - inter_area\n",
    "    \n",
    "    return inter_area/union_area\n",
    "\n",
    "\n",
    "def nms(inputs=None, NMS_TRESH=None):\n",
    "    for i in range(inputs.shape[0]-1):\n",
    "        b1 = inputs[i]\n",
    "        if b1[4] == 0:\n",
    "            continue\n",
    "        for j in range(i+1, inputs.shape[0]):\n",
    "            b2 = inputs[j]\n",
    "            if b1[5] == b2[5] and b2[4] > 0: #If same label\n",
    "                iou_score = iou(b1[:4], b2[:4])\n",
    "                if iou_score > NMS_TRESH:\n",
    "                    inputs[j,4] = 0\n",
    "                #print('Box {}, {}\\n{}\\n{}\\n{}'.format(i, j, b1[:4], b2[:4], iou(b1[:4], b2[:4])))\n",
    "    \n",
    "    return inputs[inputs[:,4] > 0]\n",
    "\n",
    "\n",
    "def draw_boxes(img, inputs):\n",
    "    scale = min(HEIGHT/img.shape[0], WIDTH/img.shape[1])\n",
    "    offset_x = (WIDTH - img.shape[1]*scale)/2\n",
    "    offset_y = (HEIGHT - img.shape[0]*scale)/2\n",
    "    \n",
    "    colors = np.random.uniform(0, 255, size=(80, 3))\n",
    "    \n",
    "    for b in inputs:\n",
    "        x_min = int((b[0]-offset_x) / scale)\n",
    "        x_max = int((b[2]-offset_x) / scale)\n",
    "        y_min = int((b[1]-offset_y) / scale)\n",
    "        y_max = int((b[3]-offset_y) / scale)\n",
    "        \n",
    "        label = int(b[5])\n",
    "        color = colors[label]\n",
    "        \n",
    "        cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color, 1)\n",
    "        cv2.putText(img, \n",
    "                    LABELS[label], \n",
    "                    (x_min, y_min-5), \n",
    "                    cv2.FONT_HERSHEY_PLAIN, \n",
    "                    1, \n",
    "                    color,\n",
    "                    1)\n",
    "        \n",
    "    return img\n",
    "\n",
    "\n",
    "def process_output(result=None):\n",
    "    # Select label & score at bouding boxes\n",
    "    max_pos = torch.argmax(result[:,5:], 1) #labels with highest score\n",
    "    max_score = result[torch.arange(result.size(0)), max_pos+5] #score of that labels\n",
    "    result = torch.cat((result[:,:5], max_pos.float().unsqueeze(1), max_score.unsqueeze(1)), 1) #downside result\n",
    "    \n",
    "    # Turn xywh to xyxy and round it + Sort by po\n",
    "    result[:,:4] = xywh2wywy(result[:,:4]).round()\n",
    "    result = result[torch.argsort(result[:,4], descending=True)] #Sort by bouding box score\n",
    "    \n",
    "    \n",
    "    # Do non max suppession\n",
    "    result = nms(inputs=result, NMS_TRESH=NMS_THRESH)\n",
    "    \n",
    "    # Draw boxes\n",
    "    _img = draw_boxes(img, result)\n",
    "    \n",
    "    return (_img, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T12:56:56.500313Z",
     "start_time": "2020-05-03T12:56:56.487310Z"
    }
   },
   "outputs": [],
   "source": [
    "_img, res = process_output(result)\n",
    "cv2.imshow(\"test\", _img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9977,  0.0000,  0.9993],\n",
       "        [ 0.9906,  0.0000,  0.9996],\n",
       "        [ 0.9862,  0.0000,  0.9999],\n",
       "        [ 0.9823,  0.0000,  0.9999],\n",
       "        [ 0.9810,  0.0000,  0.9998],\n",
       "        [ 0.8458, 26.0000,  0.9904],\n",
       "        [ 0.7545,  0.0000,  0.9997],\n",
       "        [ 0.7540, 13.0000,  0.9962],\n",
       "        [ 0.5296,  1.0000,  0.9938],\n",
       "        [ 0.4900, 73.0000,  0.9986],\n",
       "        [ 0.4552,  0.0000,  0.9998],\n",
       "        [ 0.4308, 73.0000,  0.9991],\n",
       "        [ 0.4054, 13.0000,  0.9146],\n",
       "        [ 0.3979, 73.0000,  0.9992],\n",
       "        [ 0.3902, 73.0000,  0.9981],\n",
       "        [ 0.3865, 73.0000,  0.9983],\n",
       "        [ 0.3590, 73.0000,  0.9993],\n",
       "        [ 0.3546, 73.0000,  0.9983],\n",
       "        [ 0.3520, 73.0000,  0.9959],\n",
       "        [ 0.3405, 73.0000,  0.9986],\n",
       "        [ 0.3302, 73.0000,  0.9969],\n",
       "        [ 0.3288, 73.0000,  0.9986],\n",
       "        [ 0.3257, 73.0000,  0.9980],\n",
       "        [ 0.3072, 73.0000,  0.9982],\n",
       "        [ 0.3042, 73.0000,  0.9975]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3606)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou(res[7,:4], res[12,:4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xpython",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "326.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 929.313,
   "position": {
    "height": "853.313px",
    "left": "1499.66px",
    "right": "20px",
    "top": "116px",
    "width": "341.641px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
